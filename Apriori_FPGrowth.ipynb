{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiWut7jTOr6w"
      },
      "outputs": [],
      "source": [
        "from apyori import apriori\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pyfpgrowth\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"breast-cancer_cleaned.csv\")\n",
        "\n",
        "df['diagnosis'] = df['diagnosis'].map({1: 'malignant', 0: 'benign'})\n",
        "\n",
        "def get_range_labels(data, num_bins):\n",
        "    bins = pd.qcut(data, num_bins, retbins=True)[1]\n",
        "    return [f'{bins[i]:.2f}to{bins[i+1]:.2f}' for i in range(len(bins)-1)]\n"
      ],
      "metadata": {
        "id": "mDKlIsrvO0DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Shapiro-Wilk Test Results"
      ],
      "metadata": {
        "id": "oWx6cL-qO922"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for column in df.columns[:-1]:\n",
        "    stat, p_value = stats.shapiro(df[column])\n",
        "    print(f\"{column}: Statistic = {stat:.4f}, p-value = {p_value:.4e}\")\n",
        "print(\"-\" * 50)\n",
        "#kda data not normally distributed\n",
        "\n"
      ],
      "metadata": {
        "id": "KqvQQfhfO56t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get bins numbers"
      ],
      "metadata": {
        "id": "HjQQyIrTPIxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Discretize numerical columns beeee Freedman-Diaconis Rule\n",
        "bins_array = []  # Store number of bins for each column\n",
        "for column in df.columns[:-1]:\n",
        "\n",
        "    col_data = df[column]\n",
        "\n",
        "    # Calculate IQR\n",
        "    q1 = np.percentile(col_data, 25)\n",
        "    q3 = np.percentile(col_data, 75)\n",
        "    iqr = q3 - q1\n",
        "\n",
        "    # Bin Width and Number of Bins\n",
        "    bin_width = 2 * iqr / len(col_data) ** (1 / 3)\n",
        "    num_bins = int(np.ceil((col_data.max() - col_data.min()) / bin_width))\n",
        "    bins_array.append((column, num_bins))\n",
        "    # Create custom labels for the bins based on value ranges\n",
        "    bin_labels = get_range_labels(col_data, num_bins)\n",
        "    # Discretize the column into bins\n",
        "    df[column] = pd.cut(df[column], bins=num_bins, labels=bin_labels)\n",
        "    print(f\"Column: {column}, Bins: {num_bins}\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "cbEeVy44PHnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "transactions = []\n",
        "for i in range(len(df)):\n",
        "    transaction = []\n",
        "    for col in df.columns:\n",
        "        value = df[col][i]\n",
        "        if pd.notna(value):\n",
        "            transaction.append(f\"{col}={value}\")\n",
        "    transactions.append(transaction)\n"
      ],
      "metadata": {
        "id": "3qPRShKFPRLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Apply Apriori Algorithm\n",
        "association_rules = apriori(transactions, min_support=0.05, min_confidence=0.6)\n",
        "association_results = list(association_rules)\n",
        "\n",
        "# Display Results in Predicate Format\n",
        "print(\"Association Rules in Predicate Format:\\n\")\n",
        "for rule in association_results:\n",
        "    for ordered_stat in rule.ordered_statistics:\n",
        "        if ordered_stat.confidence >= 0.6:  # Filter by confidence threshold\n",
        "            antecedent = \", \".join(\n",
        "                [f\"{item.split('=')[0]}({item.split('=')[1]})\" for item in ordered_stat.items_base]\n",
        "            )\n",
        "            consequent = \", \".join(\n",
        "                [f\"{item.split('=')[0]}({item.split('=')[1]})\" for item in ordered_stat.items_add]\n",
        "            )\n",
        "            print(\n",
        "                f\"{antecedent} -> {consequent} (support: {rule.support:.2f}, confidence: {ordered_stat.confidence:.2f})\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jTqzt0C-PTmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "FrequentPatterns = pyfpgrowth.find_frequent_patterns(transactions=transactions, support_threshold=26)  # Same as 0.05 support\n",
        "FrequentPatterns\n",
        "\n",
        "# Generate association rules with confidence threshold of 0.6\n",
        "Rules = pyfpgrowth.generate_association_rules(patterns=FrequentPatterns, confidence_threshold=0.6)\n",
        "\n",
        "print(\"Association Rules in Predicate Format:\\n\")\n",
        "# Print the rules in predicate format\n",
        "for antecedent, (consequent, confidence) in Rules.items():\n",
        "    # Convert antecedent and consequent to string representations for readability\n",
        "    antecedent_str = \", \".join(antecedent)\n",
        "    consequent_str = \", \".join(consequent)\n",
        "\n",
        "    print(f\"({antecedent_str}) â‡’ ({consequent_str}) with confidence {confidence}\")"
      ],
      "metadata": {
        "id": "XidytdN3PdHv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}